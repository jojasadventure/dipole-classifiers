#!/usr/bin/env python
import argparse
import sys
import json
import csv
import numpy as np
from pathlib import Path
from tqdm import tqdm

# Add project root to path
sys.path.append(str(Path(__file__).resolve().parent.parent))

from core.log_setup import setup_logging
from core.embedding import EmbeddingGenerator
from core.classifier import DimensionClassifier

try:
    from datasets import load_from_disk, load_dataset
except ImportError:
    sys.exit("Error: 'datasets' library missing. Install with: pip install datasets")

class _Colors:
    RED = '\033[91m'    # Pole B (High Score)
    GREEN = '\033[92m'  # Pole A (Low Score)
    CYAN = '\033[96m'   # Metadata
    BOLD = '\033[1m'
    ENDC = '\033[0m'

def define_args():
    parser = argparse.ArgumentParser(description="Pre-sort and filter a dataset using a dimension vector.")
    
    # Core Inputs
    parser.add_argument('--vector', type=Path, required=True, help='Path to dimension_vector.json')
    parser.add_argument('--dataset', type=str, required=True, help='Path to local dataset, JSONL cache, or HF ID')
    parser.add_argument('--column', type=str, default='text', help='Column name to analyze (for raw datasets)')
    
    # Metadata
    parser.add_argument('--include-cols', nargs='+', default=[], help='List of other columns to display/export')
    
    # Triage Settings
    parser.add_argument('--limit', type=int, default=0, help='Test on first N rows only (0 = all)')
    parser.add_argument('--threshold', type=float, default=0.1, help='Save items with score > X to CSV. Set to -1 to save all.')
    
    # Outputs
    parser.add_argument('--output-csv', type=str, default='investigation_results.csv', help='CSV filename for hits')
    parser.add_argument('--show', type=int, default=5, help='Display top N results for each pole on CLI')

    # System
    parser.add_argument('--config', default='config.yaml', help='Config file path')
    parser.add_argument('--embedding-api-url', type=str)
    parser.add_argument('--embedding-model-id', type=str)

    return parser.parse_args()

def main():
    args = define_args()
    setup_logging()

    # 1. CONFIGURATION & INITIALIZATION
    config = {}
    if Path(args.config).exists():
        import yaml
        with open(args.config, 'r') as f: config = yaml.safe_load(f)
    
    api_url = args.embedding_api_url or config.get('embedding_api_url')
    model_id = args.embedding_model_id or config.get('embedding_model_id')
    
    if not args.vector.exists():
        sys.exit(f"Vector file not found: {args.vector}")

    # Initialize Embedder & Classifier
    # We need the classifier to robustly get the Vector Array and Pole Names
    embedder = EmbeddingGenerator(base_url=api_url, model_name=model_id)
    classifier = DimensionClassifier(args.vector, embedder)

    # Extract Critical Data from Classifier
    pole_a = classifier.poles.get('a', 'Pole A')
    pole_b = classifier.poles.get('b', 'Pole B')
    dimension_vector = classifier.vector # Numpy array needed for Cache Math

    # 2. METADATA CHECK (Restored)
    # We manually peek at the JSON file to get the 'embedding_model' string for safety checks
    # (DimensionClassifier doesn't expose the raw metadata dict publicly)
    vector_model_name = None
    try:
        with open(args.vector, 'r') as f:
            raw_vec_data = json.load(f)
            if 'metadata' in raw_vec_data:
                vector_model_name = raw_vec_data['metadata'].get('embedding_model')
    except Exception:
        pass # Non-fatal if metadata missing

    print(f"--- Investigating ---")
    print(f"Vector:  {pole_a} <-> {pole_b}")
    if vector_model_name:
        print(f"Vector Model: {vector_model_name}")

    results = []
    
    # 3. DETERMINE INPUT TYPE
    is_jsonl = str(args.dataset).endswith('.jsonl')

    if is_jsonl:
        # --- CACHED MODE ---
        print(f"Dataset: {args.dataset} (Cached Mode)")
        
        with open(args.dataset, 'r', encoding='utf-8') as f:
            # Header Check
            first_line = f.readline()
            if not first_line:
                sys.exit("Error: JSONL file is empty.")
            
            try:
                header = json.loads(first_line)
                if header.get("meta") is True:
                    cached_model = header.get("embedding_model")
                    print(f"Cache Model:  {cached_model}")
                    
                    # SAFETY CHECK: Vector vs Cache
                    if vector_model_name and cached_model and vector_model_name != cached_model:
                        print(f"{_Colors.RED}WARNING: Model mismatch detected!{_Colors.ENDC}")
                        print(f"Vector trained on: {vector_model_name}")
                        print(f"Cache generated by: {cached_model}")
                        print("Results will be garbage. Press Ctrl+C to abort or Enter to continue anyway.")
                        input()
                else:
                    f.seek(0) # No header, reset
            except json.JSONDecodeError:
                sys.exit("Error: Failed to decode JSONL.")

            # Read Data
            lines = f.readlines()
            if args.limit > 0:
                print(f"Slicing to first {args.limit} rows.")
                lines = lines[:args.limit]
            
            print("Calculating scores from cache...")
            for line in tqdm(lines, unit="doc"):
                record = json.loads(line)
                
                # MATH: Dot Product (Cache Vector * Dimension Vector)
                emb = np.array(record['vector'])
                score = float(np.dot(emb, dimension_vector))
                
                res = {
                    'row_index': record.get('row_index', 0),
                    'score': score,
                    'text': record.get('text', '')
                }
                
                # Extra Cols
                if args.include_cols:
                    for col in args.include_cols:
                        res[col] = record.get(col, 'N/A')
                
                results.append(res)

    else:
        # --- RAW DATASET MODE (Live Embedding) ---
        print(f"Dataset: {args.dataset} (Live Embedding Mode)")
        
        # SAFETY CHECK: Vector vs Config
        if vector_model_name and model_id and vector_model_name != model_id:
             print(f"{_Colors.RED}WARNING: Configured embedder ({model_id}) differs from vector model ({vector_model_name}).{_Colors.ENDC}")

        # Load Data
        if Path(args.dataset).exists():
            ds = load_from_disk(args.dataset)
        else:
            ds = load_dataset(args.dataset, split='train')

        total_rows = len(ds)
        if args.limit > 0 and args.limit < total_rows:
            print(f"Slicing to first {args.limit} documents.")
            ds = ds.select(range(args.limit))
            texts = ds[args.column]
        else:
            texts = ds[args.column]

        # Verify extra columns
        if args.include_cols:
            valid_cols = [c for c in args.include_cols if c in ds.column_names]
            args.include_cols = valid_cols

        # Run Classification
        BATCH_SIZE = 100
        print("Calculating scores...")
        with tqdm(total=len(texts), unit="doc") as pbar:
            for i in range(0, len(texts), BATCH_SIZE):
                batch_texts = texts[i:i+BATCH_SIZE]
                batch_results = classifier.classify(batch_texts)
                
                for j, res in enumerate(batch_results):
                    global_idx = i + j
                    res['row_index'] = global_idx
                    
                    if args.include_cols:
                        for col in args.include_cols:
                            res[col] = ds[global_idx][col]

                results.extend(batch_results)
                pbar.update(len(batch_texts))

    # 4. SORT & DISPLAY
    results.sort(key=lambda x: x['score'], reverse=True)

    def print_entry(item, color_code):
        score_str = f"{color_code}[Score: {item['score']:.4f}]{_Colors.ENDC}"
        idx_str = f"{_Colors.CYAN}[Row: {item['row_index']}]{_Colors.ENDC}"
        
        meta_str = ""
        if args.include_cols:
            meta_parts = [f"{c}: {item.get(c, 'N/A')}" for c in args.include_cols]
            meta_str = f" | {', '.join(meta_parts)}"

        print(f"{score_str} {idx_str}{meta_str}")
        print(f"{item['text']}")
        print("-" * 80)

    print(f"\n{_Colors.BOLD}=== TOP {args.show} '{pole_b.upper()}' (Highest Scores) ==={_Colors.ENDC}")
    print("-" * 80)
    for item in results[:args.show]:
        print_entry(item, _Colors.RED)

    print(f"\n{_Colors.BOLD}=== TOP {args.show} '{pole_a.upper()}' (Lowest Scores) ==={_Colors.ENDC}")
    print("-" * 80)
    for item in reversed(results[-args.show:]):
        print_entry(item, _Colors.GREEN)

    # 5. EXPORT TO CSV
    if args.threshold <= -1.0:
        hits = results
        print(f"\nThreshold set to -1: Exporting ALL {len(hits)} rows.")
    else:
        hits = [r for r in results if r['score'] >= args.threshold]
        print(f"\nExporting {len(hits)} items (Score >= {args.threshold})...")
    
    if hits:
        # Dynamic Header
        score_header = f"score_{pole_b.replace(' ', '_')}"
        fieldnames = ['row_index', score_header] + args.include_cols
        
        with open(args.output_csv, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for r in hits:
                row_data = {
                    'row_index': r['row_index'],
                    score_header: f"{r['score']:.5f}"
                    # 'text': r['text'] # <-- Excluded
                }
                for col in args.include_cols:
                    row_data[col] = r.get(col, '')
                
                writer.writerow(row_data)
                
        print(f"Saved to '{args.output_csv}'.")
    else:
        print(f"\nNo items found above threshold {args.threshold}.")

if __name__ == "__main__":
    main()