# -----------------------------------------------------------------
# The embedding service settings below are pre-configured to work with
# the CPU Docker command provided in the README Quick Start.
#
# You only need to add your LLM API key to get started.
# -----------------------------------------------------------------

# --- LLM Configuration for Data Generation ---
# Options for llm_provider: "google", "openai", "ollama"
llm_provider: "openai"
llm_api_key: "sk-add-your-api-key-here"
# for openai compatible or ollama: change your llm_api_url
llm_api_url: null
llm_model_name: "gpt-4o"
llm_temperature: 0.7
llm_num_pairs: 50
llm_batch_size: 20

# --- Embedding Model Configuration (Pre-configured for Quick Start) ---
embedding_api_url: "http://localhost:8080"
embedding_model_id: "nomic-ai/nomic-embed-text-v1.5"
embedding_api_key: null # No key needed for local TEI

# --- Pipeline Behavior Configuration ---
pipeline_run_validation_by_default: false
pipeline_num_validation_samples: 25
pipeline_validation_pairs_override_path: null